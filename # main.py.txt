# main.py
import os
import hashlib
import asyncio
import aiohttp
from urllib.parse import urlparse
import yt_dlp
from playwright.async_api import async_playwright
import cv2
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
import json
import tempfile
import speech_recognition as sr
from pydub import AudioSegment
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
import uuid
import aiofiles
from datetime import datetime
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ========== MODELOS PYDANTIC ==========
class AnalysisRequest(BaseModel):
    content: str
    content_type: str  # "link" o "video/image"
    request_id: Optional[str] = None

class AnalysisResponse(BaseModel):
    request_id: str
    status: str  # "completed", "processing", "error"
    result: Optional[Dict] = None
    error_message: Optional[str] = None

# ========== CLASE LINK RESOLVER ==========
class LinkResolver:
    def __init__(self, cache_dir: str = "./cache"):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
        
    def _generate_cache_key(self, url: str) -> str:
        """Genera una clave única para el cache basada en la URL"""
        return hashlib.md5(url.encode()).hexdigest()
    
    async def resolve_video(self, social_media_url: str) -> Dict:
        """
        Resuelve una URL de red social a un enlace directo de video
        
        Args:
            social_media_url: URL de TikTok, Instagram, YouTube, Twitter/X, Facebook
            
        Returns:
            Dict con URL directa al video y metadata básica
        """
        # Verificar si ya tenemos este resultado en cache
        cache_key = self._generate_cache_key(social_media_url)
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        
        if os.path.exists(cache_file):
            async with aiofiles.open(cache_file, 'r') as f:
                content = await f.read()
                return json.loads(content)
        
        # Intentar con yt-dlp primero
        result = await self._try_yt_dlp(social_media_url)
        
        # Si falla, intentar con Puppeteer/Playwright
        if not result or 'video_url' not in result:
            result = await self._try_headless_browser(social_media_url)
        
        # Guardar en cache si se obtuvo un resultado válido
        if result and 'video_url' in result:
            async with aiofiles.open(cache_file, 'w') as f:
                await f.write(json.dumps(result))
        
        return result if result else {}
    
    async def _try_yt_dlp(self, url: str) -> Optional[Dict]:
        """Intenta resolver el video usando yt-dlp"""
        ydl_opts = {
            'format': 'best[ext=mp4]/best',
            'quiet': True,
            'no_warnings': True,
            'force_json': True,
            'noplaylist': True,
        }
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                
                if info and 'url' in info:
                    return {
                        'video_url': info['url'],
                        'title': info.get('title', ''),
                        'duration': info.get('duration', 0),
                        'thumbnail': info.get('thumbnail', ''),
                        'platform': info.get('extractor', ''),
                        'resolution': f"{info.get('width', 0)}x{info.get('height', 0)}"
                    }
        except Exception as e:
            logger.error(f"Error con yt-dlp: {e}")
            return None
        
        return None
    
    async def _try_headless_browser(self, url: str) -> Optional[Dict]:
        """Intenta resolver el video usando un navegador headless"""
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context()
            page = await context.new_page()
            
            try:
                await page.goto(url, wait_until='networkidle')
                
                # Estrategia genérica para extraer videos
                video_url = await self._extract_generic_video(page)
                
                if video_url:
                    platform = self._identify_platform(url)
                    return {
                        'video_url': video_url,
                        'platform': platform,
                        'method': 'headless_browser'
                    }
                    
            except Exception as e:
                logger.error(f"Error con headless browser: {e}")
            finally:
                await browser.close()
        
        return None
    
    def _identify_platform(self, url: str) -> str:
        """Identifica la plataforma basada en la URL"""
        domain = urlparse(url).netloc.lower()
        
        if 'tiktok.com' in domain:
            return 'tiktok'
        elif 'instagram.com' in domain:
            return 'instagram'
        elif 'youtube.com' in domain or 'youtu.be' in domain:
            return 'youtube'
        elif 'twitter.com' in domain or 'x.com' in domain:
            return 'twitter'
        elif 'facebook.com' in domain or 'fb.com' in domain:
            return 'facebook'
        else:
            return 'unknown'
    
    async def _extract_generic_video(self, page) -> Optional[str]:
        """Intenta extraer URL de video de forma genérica"""
        try:
            # Buscar elementos de video
            video_elements = await page.query_selector_all('video')
            for video in video_elements:
                src = await video.get_attribute('src')
                if src and (src.endswith('.mp4') or 'video' in src):
                    return src
            
            # Buscar iframes con contenido de video
            iframe_elements = await page.query_selector_all('iframe')
            for iframe in iframe_elements:
                src = await iframe.get_attribute('src')
                if src and ('youtube' in src or 'vimeo' in src or 'video' in src):
                    return src
                    
        except Exception as e:
            logger.error(f"Error extrayendo video: {e}")
        
        return None

# ========== CLASE ADVANCED CONTENT ANALYZER ==========
class AdvancedContentAnalyzer:
    def __init__(self):
        self.video_analyzers = [
            self._analyze_video_artifacts,
            self._analyze_temporal_consistency,
            self._analyze_facial_patterns
        ]
        
        self.audio_analyzers = [
            self._analyze_audio_tts,
            self._analyze_audio_quality
        ]
        
        self.metadata_analyzers = [
            self._analyze_technical_metadata,
            self._analyze_creation_patterns
        ]
    
    async def advanced_analysis(self, video_url: str) -> Dict:
        """
        Realiza análisis avanzado de contenido para detectar si fue generado por IA
        
        Args:
            video_url: URL directa al video
            
        Returns:
            Objeto con análisis detallado
        """
        # Descargar el video temporalmente
        video_path = await self._download_video(video_url)
        
        if not video_path:
            return self._create_error_response("No se pudo descargar el video")
        
        try:
            # Ejecutar análisis en paralelo
            video_analysis = await self._analyze_video(video_path)
            audio_analysis = await self._analyze_audio(video_path)
            metadata_analysis = await self._analyze_metadata(video_path)
            
            # Combinar resultados
            combined_analysis = self._combine_analyses(
                video_analysis, audio_analysis, metadata_analysis
            )
            
            return combined_analysis
            
        except Exception as e:
            logger.error(f"Error en análisis avanzado: {e}")
            return self._create_error_response(f"Error en análisis: {str(e)}")
        finally:
            # Limpiar archivo temporal
            if os.path.exists(video_path):
                os.remove(video_path)
    
    async def _download_video(self, video_url: str, max_duration: int = 90) -> Optional[str]:
        """Descarga el video y limita la duración si es necesario"""
        try:
            # Crear archivo temporal
            temp_file = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False)
            temp_path = temp_file.name
            temp_file.close()
            
            # Descargar el video usando aiohttp
            async with aiohttp.ClientSession() as session:
                async with session.get(video_url) as response:
                    if response.status == 200:
                        async with aiofiles.open(temp_path, 'wb') as f:
                            async for chunk in response.content.iter_chunked(1024 * 1024):
                                await f.write(chunk)
                        return temp_path
            
            return None
        except Exception as e:
            logger.error(f"Error descargando video: {e}")
            return None
    
    async def _analyze_video(self, video_path: str) -> Dict:
        """Ejecuta todos los análisis de video"""
        results = {}
        
        for analyzer in self.video_analyzers:
            try:
                analysis = await analyzer(video_path)
                results.update(analysis)
            except Exception as e:
                logger.error(f"Error en análisis de video: {e}")
        
        return results
    
    async def _analyze_audio(self, video_path: str) -> Dict:
        """Ejecuta todos los análisis de audio"""
        # Extraer audio del video
        audio_path = await self._extract_audio(video_path)
        
        if not audio_path:
            return {"audio_analysis": "failed"}
        
        results = {}
        
        try:
            for analyzer in self.audio_analyzers:
                try:
                    analysis = await analyzer(audio_path)
                    results.update(analysis)
                except Exception as e:
                    logger.error(f"Error en análisis de audio: {e}")
        finally:
            if os.path.exists(audio_path):
                os.remove(audio_path)
        
        return results
    
    async def _extract_audio(self, video_path: str) -> Optional[str]:
        """Extrae audio de un video usando pydub"""
        try:
            # Crear archivo temporal para audio
            temp_audio = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
            temp_audio_path = temp_audio.name
            temp_audio.close()
            
            # Cargar video y extraer audio
            video = AudioSegment.from_file(video_path)
            video.export(temp_audio_path, format="wav")
            
            return temp_audio_path
        except Exception as e:
            logger.error(f"Error extrayendo audio: {e}")
            return None
    
    async def _analyze_metadata(self, video_path: str) -> Dict:
        """Analiza los metadatos del archivo"""
        results = {}
        
        for analyzer in self.metadata_analyzers:
            try:
                analysis = await analyzer(video_path)
                results.update(analysis)
            except Exception as e:
                logger.error(f"Error en análisis de metadata: {e}")
        
        return results
    
    async def _analyze_video_artifacts(self, video_path: str) -> Dict:
        """Analiza artefactos comunes en videos generados por IA"""
        # Implementación simplificada - en producción usaría modelos más avanzados
        try:
            cap = cv2.VideoCapture(video_path)
            success, frame = cap.read()
            
            if success:
                # Análisis básico de frame
                blur_value = cv2.Laplacian(frame, cv2.CV_64F).var()
                
                # Simular detección de artefactos
                ai_score = min(90, max(10, int(blur_value / 10)))
                
                return {
                    "video_artifacts": {
                        "score": ai_score / 100,
                        "confidence": 0.7,
                        "indicators": ["consistent_noise_pattern", "unnatural_edges"] if ai_score > 70 else []
                    }
                }
        except Exception as e:
            logger.error(f"Error analizando artefactos de video: {e}")
        
        return {
            "video_artifacts": {
                "score": 0.5,
                "confidence": 0.5,
                "indicators": []
            }
        }
    
    async def _analyze_temporal_consistency(self, video_path: str) -> Dict:
        """Analiza la consistencia temporal entre frames"""
        # Implementación simplificada
        return {
            "temporal_consistency": {
                "score": 0.62,
                "confidence": 0.7,
                "indicators": ["frame_jitter", "inconsistent_lighting"]
            }
        }
    
    async def _analyze_facial_patterns(self, video_path: str) -> Dict:
        """Analiza patrones faciales para detectar caras generadas por IA"""
        # Implementación simplificada
        return {
            "facial_analysis": {
                "score": 0.85,
                "confidence": 0.9,
                "face_count": 1,
                "indicators": ["unnatural_blinking", "consistent_symmetry"]
            }
        }
    
    async def _analyze_audio_tts(self, audio_path: str) -> Dict:
        """Analiza audio para detectar voz sintética o TTS"""
        # Implementación simplificada
        return {
            "audio_tts_analysis": {
                "score": 0.68,
                "confidence": 0.75,
                "indicators": ["unnatural_pauses", "consistent_pitch"]
            }
        }
    
    async def _analyze_audio_quality(self, audio_path: str) -> Dict:
        """Analiza la calidad del audio"""
        # Implementación simplificada
        return {
            "audio_quality": {
                "score": 0.8,
                "confidence": 0.8,
                "indicators": ["consistent_bitrate", "no_background_noise"]
            }
        }
    
    async def _analyze_technical_metadata(self, video_path: str) -> Dict:
        """Analiza metadatos técnicos del archivo"""
        # Implementación simplificada
        return {
            "technical_metadata": {
                "software_indicators": [],
                "creation_pattern": "normal",
                "compression_artifacts": "standard"
            }
        }
    
    async def _analyze_creation_patterns(self, video_path: str) -> Dict:
        """Analiza patrones de creación"""
        # Implementación simplificada
        return {
            "creation_patterns": {
                "score": 0.4,
                "confidence": 0.6,
                "indicators": []
            }
        }
    
    def _combine_analyses(self, video_analysis: Dict, audio_analysis: Dict, metadata_analysis: Dict) -> Dict:
        """Combina todos los análisis en un resultado unificado"""
        # Calcular probabilidad general basada en todos los análisis
        ai_probability = self._calculate_ai_probability(video_analysis, audio_analysis, metadata_analysis)
        
        # Determinar veredicto
        if ai_probability > 75:
            verdict = "probable_ai"
        elif ai_probability < 25:
            verdict = "probable_organic"
        else:
            verdict = "mixed"
        
        # Crear resumen explicativo
        summary = self._generate_summary(ai_probability, verdict, video_analysis, audio_analysis, metadata_analysis)
        
        # Extraer indicadores clave
        key_indicators = self._extract_key_indicators(video_analysis, audio_analysis, metadata_analysis)
        
        return {
            "ai_probability": ai_probability,
            "verdict": verdict,
            "summary": summary,
            "key_indicators": key_indicators,
            "vendor_votes": {
                "video_analysis": video_analysis,
                "audio_analysis": audio_analysis,
                "metadata_analysis": metadata_analysis
            }
        }
    
    def _calculate_ai_probability(self, video_analysis: Dict, audio_analysis: Dict, metadata_analysis: Dict) -> int:
        """Calcula la probabilidad general de que el contenido sea generado por IA"""
        # Ponderar diferentes análisis
        video_score = video_analysis.get('video_artifacts', {}).get('score', 0.5) * 0.5
        temporal_score = video_analysis.get('temporal_consistency', {}).get('score', 0.5) * 0.3
        audio_score = audio_analysis.get('audio_tts_analysis', {}).get('score', 0.5) * 0.2
        
        total_score = (video_score + temporal_score + audio_score) * 100
        return int(max(0, min(100, total_score)))
    
    def _generate_summary(self, ai_probability: int, verdict: str, 
                         video_analysis: Dict, audio_analysis: Dict, 
                         metadata_analysis: Dict) -> str:
        """Genera un resumen explicativo del análisis"""
        if verdict == "probable_ai":
            return "El análisis sugiere que este contenido tiene una alta probabilidad de haber sido generado por IA, basado en patrones visuales consistentes, artefactos de compresión y metadatos."
        elif verdict == "probable_organic":
            return "El análisis sugiere que este contenido es probablemente orgánico, con patrones naturales y consistencia esperada en contenido humano."
        else:
            return "El análisis es mixto, con algunos indicadores que sugieren posible generación por IA pero no concluyentes. Se recomienda análisis adicional."
    
    def _extract_key_indicators(self, video_analysis: Dict, audio_analysis: Dict, 
                               metadata_analysis: Dict) -> List[Dict]:
        """Extrae los indicadores clave del análisis"""
        indicators = []
        
        # Extraer de video_analysis
        if "video_artifacts" in video_analysis:
            for indicator in video_analysis["video_artifacts"].get("indicators", []):
                indicators.append({
                    "indicator": indicator,
                    "description": f"Artefacto visual: {indicator}",
                    "confidence": video_analysis["video_artifacts"].get("confidence", 0.5)
                })
        
        # Extraer de audio_analysis
        if "audio_tts_analysis" in audio_analysis:
            for indicator in audio_analysis["audio_tts_analysis"].get("indicators", []):
                indicators.append({
                    "indicator": indicator,
                    "description": f"Artefacto de audio: {indicator}",
                    "confidence": audio_analysis["audio_tts_analysis"].get("confidence", 0.5)
                })
        
        return indicators
    
    def _create_error_response(self, message: str) -> Dict:
        """Crea una respuesta de error estandarizada"""
        return {
            "error": True,
            "message": message,
            "ai_probability": 0,
            "verdict": "unknown",
            "summary": f"Error en el análisis: {message}"
        }

# ========== CLASE COST MANAGER ==========
class CostManager:
    def __init__(self):
        self.cost_per_analysis = 0.05  # USD por análisis
        self.plan_limits = {
            "free": {"monthly_analyses": 100, "max_duration": 60},
            "basic": {"monthly_analyses": 1000, "max_duration": 90},
            "pro": {"monthly_analyses": 10000, "max_duration": 120}
        }
    
    def check_analysis_limit(self, user_plan: str, analyses_this_month: int) -> bool:
        """Verifica si el usuario ha excedido su límite mensual"""
        limit = self.plan_limits.get(user_plan, {}).get("monthly_analyses", 0)
        return analyses_this_month < limit
    
    def calculate_cost(self, duration: float, user_plan: str) -> float:
        """Calcula el costo de un análisis basado en la duración y el plan"""
        base_cost = self.cost_per_analysis
        plan_modifier = 1.0
        
        if user_plan == "pro":
            plan_modifier = 0.8  # 20% de descuento para plan pro
        elif user_plan == "basic":
            plan_modifier = 0.9  # 10% de descuento para plan basic
            
        # El costo aumenta con la duración del video
        duration_factor = 1.0 + (duration / 60) * 0.5
        
        return base_cost * plan_modifier * duration_factor

# ========== CLASE PRINCIPAL AI SEE ANALYZER ==========
class AISeeAnalyzer:
    def __init__(self):
        self.link_resolver = LinkResolver()
        self.content_analyzer = AdvancedContentAnalyzer()
        self.cost_manager = CostManager()
        self.analysis_tracking = {}  # Para tracking de análisis por usuario
    
    async def analyze_content(self, content: str, content_type: str, user_id: str = "default") -> Dict:
        """
        Función principal para analizar contenido
        
        Args:
            content: URL o contenido a analizar
            content_type: "link" o "video/image"
            user_id: ID del usuario para tracking de límites
            
        Returns:
            Resultados del análisis
        """
        # Verificar límites de usuario (implementación simplificada)
        user_plan = "free"  # En producción, esto vendría de una base de datos
        analyses_count = self.analysis_tracking.get(user_id, {}).get('count', 0)
        
        if not self.cost_manager.check_analysis_limit(user_plan, analyses_count):
            return self._create_error_response("Límite de análisis mensual excedido")
        
        # Actualizar contador
        if user_id not in self.analysis_tracking:
            self.analysis_tracking[user_id] = {'count': 0, 'last_analysis': datetime.now()}
        self.analysis_tracking[user_id]['count'] += 1
        
        if content_type == "link":
            # Resolver enlace a video
            video_info = await self.link_resolver.resolve_video(content)
            
            if not video_info or 'video_url' not in video_info:
                return self._create_error_response("No se pudo resolver el enlace de video")
            
            # Realizar análisis avanzado
            analysis_result = await self.content_analyzer.advanced_analysis(video_info['video_url'])
            
            # Añadir información de la resolución
            analysis_result['source_info'] = video_info
            
            return analysis_result
            
        elif content_type in ["video", "image"]:
            # Análisis directo del contenido
            return await self.content_analyzer.advanced_analysis(content)
        
        else:
            return self._create_error_response(f"Tipo de contenido no soportado: {content_type}")
    
    def _create_error_response(self, message: str) -> Dict:
        """Crea una respuesta de error estandarizada"""
        return {
            "error": True,
            "message": message,
            "ai_probability": 0,
            "verdict": "unknown",
            "summary": f"Error en el análisis: {message}"
        }

# ========== CONFIGURACIÓN FASTAPI ==========
app = FastAPI(title="AI See Content Analyzer", version="1.0.0")

# Instancia global del analizador
analyzer = AISeeAnalyzer()

# Almacenamiento en memoria para requests (en producción usaría una base de datos)
analysis_requests = {}

@app.post("/analyze", response_model=AnalysisResponse)
async def analyze_content(request: AnalysisRequest, background_tasks: BackgroundTasks):
    """Endpoint principal para análisis de contenido"""
    request_id = request.request_id or str(uuid.uuid4())
    
    # Registrar la solicitud
    analysis_requests[request_id] = {
        "status": "processing",
        "request": request.dict(),
        "start_time": datetime.now()
    }
    
    # Ejecutar el análisis en segundo plano
    background_tasks.add_task(process_analysis, request_id, request)
    
    return AnalysisResponse(
        request_id=request_id,
        status="processing",
        result=None
    )

@app.get("/status/{request_id}")
async def get_analysis_status(request_id: str):
    """Endpoint para verificar el estado de un análisis"""
    if request_id not in analysis_requests:
        raise HTTPException(status_code=404, detail="Solicitud no encontrada")
    
    return analysis_requests[request_id]

async def process_analysis(request_id: str, request: AnalysisRequest):
    """Procesa el análisis en segundo plano"""
    try:
        result = await analyzer.analyze_content(
            request.content, 
            request.content_type
        )
        
        analysis_requests[request_id].update({
            "status": "completed",
            "result": result,
            "end_time": datetime.now()
        })
        
    except Exception as e:
        logger.error(f"Error procesando análisis {request_id}: {e}")
        analysis_requests[request_id].update({
            "status": "error",
            "error_message": str(e),
            "end_time": datetime.now()
        })

@app.get("/")
async def root():
    """Endpoint raíz con información del API"""
    return {
        "message": "AI See Content Analyzer API",
        "version": "1.0.0",
        "endpoints": {
            "/analyze": "POST - Analizar contenido",
            "/status/{request_id}": "GET - Verificar estado de análisis"
        }
    }

# ========== EJECUCIÓN PRINCIPAL ==========
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)